---
title: 多线程
date: 2021-10-31 13:38:25
permalink: /pages/9394e6/
categories:
  - Python
tags:
  - 
---
## 多线程不能退出？试试daemon守护进程吧
```
processing_thread = threading.Thread(target=self._processing_task_daemon_thread)
processing_thread.daemon = True
processing_thread.start()
```

## 记录multithreading的较佳实践：多线程下载（后台服务运行）
```
class ConvertUpdateVideo:
    def __init__(self, s3_client, args, debug=False):
        """
        Args:
            s3_client: s3_client object
            args: shell parameters
            debug: convert video 1-min if debug is True else full times
        """
        self.s3_client = s3_client
        self.args = args
        self.debug = debug
        self.processing_task_queue = Queue.Queue()
        self.processing_task_dic = {}
        self.lock = threading.Lock()

    def run(self):
        log_zip = self.args.logzip
        bucket = self.args.tempbucket
        tmp_folder = self.args.tmp_folder
        video_folder_name = 'video_' + log_zip
        processing_thread = threading.Thread(target=self._processing_task_daemon_thread)
        processing_thread.daemon = True
        processing_thread.start()

        while True:
            time.sleep(1)
            start_time = time.time()
            resp = self.s3_client.list_objects_v2(
                Bucket=bucket, Prefix=video_folder_name, MaxKeys=300
            )
            if int(resp['KeyCount']) == 0:
                continue

            s3path_list = [str(item['Key']) for item in resp.get('Contents')]
            for s3path in s3path_list:
                if s3path not in self.processing_task_dic:
                    # Is new download task
                    thread = threading.Thread(target=self._download_file_from_s3_thread, args=(s3path, start_time))
                    thread.start()
                    self.lock.acquire()
                    self.processing_task_dic[s3path] = thread
                    self.lock.release()

    def _download_file_from_s3_thread(self, s3path, start_time):
        """

        Args:
            s3path: The file path we will download from s3
            start_time: For time statistics

        """
        # download from s3
        bucket = self.args.tempbucket
        tmp_folder = self.args.tmp_folder
        s3_client = boto3.client('s3')

        downloaded_path = os.path.join(tmp_folder, s3path.rsplit("/", 1)[1])
        if os.path.exists(downloaded_path):
            return

        # download and unzip
        try:
            s3_client.download_file(bucket, s3path, downloaded_path)
            s3_client.delete_object(Bucket=bucket, Key=s3path)
            cmd = "unzip -u -o -q " + downloaded_path + " -d " + \
                  downloaded_path.split(".")[0]
            os.system(cmd)
        except Exception:
            Print.failed('S3 download/delete error', traceback.format_exc())
            self._tear_down(s3path, downloaded_path, '')
            return

        unzipped_dir = Sp.get_dir_with_filename(downloaded_path)

        if not os.path.isdir(unzipped_dir):
            return

        data_info_path = os.path.join(unzipped_dir, 'data_info.yml')

        with open(data_info_path, 'r') as fr:
            data_info = yaml.load(fr, Loader=yaml.FullLoader)

        # put into processing_task_queue
        self.processing_task_queue.put(self.wrapper(
            downloaded_path=downloaded_path,
            data_info=data_info,
            unzipped_dir=unzipped_dir,
            s3path=s3path,
            args=self.args,
            start_time=start_time
        ))

    def wrapper(self, **kwargs):
        def processing():
            downloaded_path = kwargs.get('downloaded_path')
            data_info = kwargs.get('data_info')
            unzipped_dir = kwargs.get('unzipped_dir')
            s3path = kwargs.get('s3path')
            args = kwargs.get('args')
            start_time = kwargs.get('start_time')

            # convert video

            # update to db

            # copy to s3mnt

            msg = 'Spend {:.3} seconds to update {} from {}' + \
                ' ({} jobs left in queue)'
            Print.success(msg.format(
                time.time() - start_time,
                target_path,
                original_path,
                str(self.processing_task_queue.qsize())
            ))
            self._tear_down(s3path, downloaded_path, unzipped_dir)
        return processing

    def _processing_task_daemon_thread(self):
        """
            1.This is a daemon thread to consume task from processing_task_queue
            2.The tasks pending on processing_task_queue produced by wrapper function

        """
        while True:
            if self.processing_task_queue.empty():
                continue

            task = self.processing_task_queue.get()
            task()

    def _tear_down(self, s3path, downloaded_path, unzipped_dir):
        """
            1. pop s3path from self.processing_task_dic
            2. delete unzipped dir or downloaded file
        Args:
            s3path: The file path we will download from s3
            downloaded_path: The downloaded path on local download from s3
            unzipped_dir: The dir unzipped by downloaded path

        """
        if os.path.exists(downloaded_path):
            os.remove(downloaded_path)

        if os.path.isdir(unzipped_dir):
            shutil.rmtree(unzipped_dir, ignore_errors=True)

        self.lock.acquire()
        if s3path in self.processing_task_dic:
            self.processing_task_dic.pop(s3path)
        self.lock.release()
```